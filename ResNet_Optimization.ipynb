{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet : Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications, Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'Data/Training_Data'\n",
    "validation_data_dir = 'Data/Validation_Data'\n",
    "test_data_dir= 'Data/Test_Data'\n",
    "\n",
    "training_features_file = 'Features/training_features_Resnet.npy'\n",
    "validation_features_file = 'Features/validation_features_Resnet.npy'\n",
    "top_weights_file = 'Weights/weights_Resnet.h5'\n",
    "model_file = 'Models/model_Resnet.h5'\n",
    "\n",
    "train_labels_file = 'Labels/training_labels.npy'\n",
    "validation_labels_file = 'Labels/validation_labels.npy'\n",
    "test_labels_file = 'Labels/test_labels.npy'\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "NB_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(open(train_labels_file, 'rb'))\n",
    "validation_labels = np.load(open(validation_labels_file, 'rb'))\n",
    "test_labels = np.load(open(test_labels_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : 307 Images\n",
      "Validation Data : 74 Images\n",
      "Test Data : 18 Images\n"
     ]
    }
   ],
   "source": [
    "print('Training Data : ' + str(len(train_labels)) + ' Images')\n",
    "print('Validation Data : ' + str(len(validation_labels)) + ' Images')\n",
    "print('Test Data : ' + str(len(test_labels)) + ' Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to feature vectors using weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_feature_vectors(model, directory, batch_size, steps):\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False) # Keep the data in the same order\n",
    "    \n",
    "    features = model.predict_generator(generator, steps, verbose=1) \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 35s 113ms/step\n",
      "Found 74 images belonging to 11 classes.\n",
      "74/74 [==============================] - 8s 112ms/step\n"
     ]
    }
   ],
   "source": [
    "# Batch size has to be a multiple of the number of images  to keep our vectors consistents\n",
    "training_batch_size = 1 # batch size for feature pre-training\n",
    "validation_batch_size = 1 # batch size for feature pre-training\n",
    "\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "training_features = images_to_feature_vectors(model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_features_file, 'wb') as file:\n",
    "        np.save(file, training_features, allow_pickle = False)\n",
    "with open(validation_features_file, 'wb') as file:\n",
    "        np.save(file, validation_features, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search CV training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr, decay, nn1, nn2, nn3, input_shape, output_shape):\n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture'''\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=lr, decay=decay)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nn1, input_dim = input_shape, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "            \n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate values\n",
    "lr=[1e-2, 1e-3, 1e-4]\n",
    "decay=[1e-6,1e-9,0]\n",
    "\n",
    "# Number of neurons per layer\n",
    "nn1=[4096,2048,1024]\n",
    "nn2=[2048,1024,512]\n",
    "nn3=[1000,500,200]\n",
    "\n",
    "batch_size=[2048,1024,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open(training_features_file, 'rb'))\n",
    "#train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "validation_data = np.load(open(validation_features_file, 'rb'))\n",
    "#validation_data = validation_data.reshape(validation_data.shape[0],-1)\n",
    "    \n",
    "train_labels_onehot = to_categorical(train_labels,NB_CLASSES)            #One Hot Encoder\n",
    "validation_labels_onehot = to_categorical(validation_labels,NB_CLASSES)  #One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary summary\n",
    "param_grid = dict(\n",
    "                    lr=lr, decay=decay, nn1=nn1, nn2=nn2, nn3=nn3,\n",
    "                    batch_size=batch_size,\n",
    "                    input_shape=train_data.shape[1:], output_shape = (NB_CLASSES,)\n",
    "                 )\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, cv=KFold(3), param_distributions=param_grid, \n",
    "                          verbose=20,  n_iter=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 52s 24ms/step - loss: 3.4681 - acc: 0.3155\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.1830 - acc: 0.9816\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0825 - acc: 0.9962\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0460 - acc: 0.9995\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 33s 15ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0041 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512, score=0.001, total= 9.3min\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 52s 25ms/step - loss: 3.2600 - acc: 0.3642\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 35s 17ms/step - loss: 0.1710 - acc: 0.9820\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0717 - acc: 0.9957\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0396 - acc: 0.9995\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 35s 17ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 35s 17ms/step - loss: 0.0036 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512, score=0.001, total= 9.6min\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 19.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 52s 25ms/step - loss: 3.5871 - acc: 0.2843\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.2347 - acc: 0.9598\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0931 - acc: 0.9957\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0542 - acc: 0.9953\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0324 - acc: 0.9995\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0167 - acc: 0.9995\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 35s 16ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 33s 16ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 34s 16ms/step - loss: 0.0042 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.0001, input_shape=2048, decay=0, batch_size=512, score=0.004, total= 9.5min\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 28.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 5.1778 - acc: 0.0222\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 2.4210 - acc: 0.4588\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.6179 - acc: 0.6131\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.3113 - acc: 0.6835\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.1542 - acc: 0.7067\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.9219 - acc: 0.7606\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.7920 - acc: 0.7772\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.7415 - acc: 0.7867\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.6680 - acc: 0.7975\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.5697 - acc: 0.8377\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.5063 - acc: 0.8453\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4598 - acc: 0.8633\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4327 - acc: 0.8775\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3971 - acc: 0.8874\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3454 - acc: 0.8978\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.2788 - acc: 0.9196\n",
      "1057/1057 [==============================] - 2s 2ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048, score=0.000, total= 1.7min\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 30.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 5.1636 - acc: 0.0222\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 2.1927 - acc: 0.5166\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.3246 - acc: 0.6887\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.1122 - acc: 0.7152\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.9810 - acc: 0.7427\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.8118 - acc: 0.7781\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.7067 - acc: 0.8155\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 5s 3ms/step - loss: 0.6232 - acc: 0.8250\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.6369 - acc: 0.8226\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.5434 - acc: 0.8458\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4304 - acc: 0.8808\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3886 - acc: 0.8983\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3920 - acc: 0.8917\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3888 - acc: 0.8869\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3154 - acc: 0.9096\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.2465 - acc: 0.9276\n",
      "1057/1057 [==============================] - 2s 2ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048, score=0.002, total= 1.7min\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 31.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 12s 6ms/step - loss: 5.1517 - acc: 0.0222\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 2.6176 - acc: 0.4342\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 5s 3ms/step - loss: 1.7786 - acc: 0.5781\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.4311 - acc: 0.6490\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.2482 - acc: 0.6741\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 1.0780 - acc: 0.7195\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.8560 - acc: 0.7668\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.7483 - acc: 0.7966\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.6884 - acc: 0.7952\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.6268 - acc: 0.8146\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.5743 - acc: 0.8344\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4715 - acc: 0.8661\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4332 - acc: 0.8746\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.4221 - acc: 0.8746\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.3650 - acc: 0.8888\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 0.2853 - acc: 0.9101\n",
      "1057/1057 [==============================] - 2s 2ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=1024, lr=0.01, input_shape=7, decay=0, batch_size=2048, score=0.003, total= 1.7min\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 33.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 3.6342 - acc: 0.2843\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.1213 - acc: 0.9849\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0423 - acc: 0.9957\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0251 - acc: 0.9981\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 19s 9ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0020 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512, score=0.004, total= 5.1min\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 38.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 3.4251 - acc: 0.3325\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.1083 - acc: 0.9806\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0387 - acc: 0.9976\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0200 - acc: 0.9995\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 17s 8ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 17s 8ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0017 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512, score=0.000, total= 5.0min\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 43.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 3.6948 - acc: 0.2602\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.1194 - acc: 0.9792\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0480 - acc: 0.9953\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0274 - acc: 0.9981\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0022 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=2048, lr=0.0001, input_shape=7, decay=1e-09, batch_size=512, score=0.004, total= 5.1min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 48.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 25s 12ms/step - loss: 3.8987 - acc: 0.2654\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.8042 - acc: 0.8373\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.4537 - acc: 0.9139\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.2823 - acc: 0.9461\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.1567 - acc: 0.9730\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.1334 - acc: 0.9735\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0904 - acc: 0.9782\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0533 - acc: 0.9920\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0515 - acc: 0.9882\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0344 - acc: 0.9953\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0278 - acc: 0.9943\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0170 - acc: 0.9981\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0182 - acc: 0.9967\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0182 - acc: 0.9967\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0088 - acc: 0.9986\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0046 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024, score=0.001, total= 3.7min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 52.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 3.8570 - acc: 0.2871\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.8959 - acc: 0.8377\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.3729 - acc: 0.9314\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.2099 - acc: 0.9532\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.1082 - acc: 0.9773\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0817 - acc: 0.9839\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0526 - acc: 0.9915\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0466 - acc: 0.9901\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0319 - acc: 0.9948\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0209 - acc: 0.9972\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0208 - acc: 0.9948\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0092 - acc: 0.9995\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0076 - acc: 0.9995\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0075 - acc: 0.9986\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0091 - acc: 0.9981\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0047 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024, score=0.000, total= 3.8min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 56.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 25s 12ms/step - loss: 3.8921 - acc: 0.2602\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.8351 - acc: 0.8009\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.4124 - acc: 0.9172\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.3160 - acc: 0.9338\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.1823 - acc: 0.9678\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.1259 - acc: 0.9730\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0841 - acc: 0.9849\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0427 - acc: 0.9939\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0369 - acc: 0.9948\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0331 - acc: 0.9962\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0236 - acc: 0.9976\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0354 - acc: 0.9943\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0151 - acc: 0.9986\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0118 - acc: 0.9986\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 13s 6ms/step - loss: 0.0087 - acc: 0.9991\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0140 - acc: 0.9972\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=1024, score=0.004, total= 3.7min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 60.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 3.7209 - acc: 0.2706\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.1774 - acc: 0.9806\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0707 - acc: 0.9962\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 17s 8ms/step - loss: 0.0373 - acc: 0.9976\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0218 - acc: 0.9995\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 17s 8ms/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 17s 8ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0029 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 3ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512, score=0.004, total= 5.0min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 65.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 3.4118 - acc: 0.3307\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.1568 - acc: 0.9787\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0622 - acc: 0.9972\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0366 - acc: 0.9976\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 19s 9ms/step - loss: 0.0026 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 3ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512, score=0.004, total= 5.1min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 70.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 32s 15ms/step - loss: 3.8325 - acc: 0.2422\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.2117 - acc: 0.9735\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0918 - acc: 0.9915\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0433 - acc: 0.9995\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0328 - acc: 0.9976\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0148 - acc: 0.9991\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 18s 9ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 0.0032 - acc: 1.0000\n",
      "1057/1057 [==============================] - 5s 5ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=2048, lr=0.0001, input_shape=2048, decay=1e-06, batch_size=512, score=0.006, total= 5.2min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 75.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 16s 8ms/step - loss: 4.4860 - acc: 0.1097\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.7217 - acc: 0.9428\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.3682 - acc: 0.9834\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.2066 - acc: 0.9972\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.1353 - acc: 0.9991\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0983 - acc: 0.9995\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0434 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 7s 4ms/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0160 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024, score=0.007, total= 2.2min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 77.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 16s 8ms/step - loss: 4.3804 - acc: 0.1301\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.7237 - acc: 0.9428\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.3635 - acc: 0.9811\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 7s 4ms/step - loss: 0.2122 - acc: 0.9953\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.1343 - acc: 0.9972\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0158 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024, score=0.003, total= 2.2min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 79.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 18s 8ms/step - loss: 4.6296 - acc: 0.0970\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.7647 - acc: 0.9309\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.3650 - acc: 0.9830\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.2128 - acc: 0.9976\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 7s 4ms/step - loss: 0.1392 - acc: 0.9991\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0997 - acc: 0.9991\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0745 - acc: 0.9986\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 7s 4ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 0.0166 - acc: 1.0000\n",
      "1057/1057 [==============================] - 3s 3ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.0001, input_shape=7, decay=0, batch_size=1024, score=0.007, total= 2.2min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 81.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 25s 12ms/step - loss: 5.3525 - acc: 0.0213\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 1.1007 - acc: 0.7744\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 12s 6ms/step - loss: 0.7357 - acc: 0.8354\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.4859 - acc: 0.9026\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.3490 - acc: 0.9338\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.2735 - acc: 0.9447\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.2142 - acc: 0.9555\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1907 - acc: 0.9612\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 12s 5ms/step - loss: 0.1770 - acc: 0.9598\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 12s 5ms/step - loss: 0.1398 - acc: 0.9626\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1004 - acc: 0.9787\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1019 - acc: 0.9773\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0996 - acc: 0.9782\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0984 - acc: 0.9782\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 12s 5ms/step - loss: 0.0814 - acc: 0.9844\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0582 - acc: 0.9915\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048, score=0.003, total= 3.4min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 85.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 5.3447 - acc: 0.0241\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 1.1702 - acc: 0.7569\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 14s 6ms/step - loss: 0.6108 - acc: 0.8765\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.4662 - acc: 0.9101\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.3661 - acc: 0.9338\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2820 - acc: 0.9371\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2503 - acc: 0.9385\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2145 - acc: 0.9508\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 14s 6ms/step - loss: 0.1514 - acc: 0.9664\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0982 - acc: 0.9816\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1046 - acc: 0.9797\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 14s 6ms/step - loss: 0.1070 - acc: 0.9787\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 14s 6ms/step - loss: 0.0989 - acc: 0.9792\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0709 - acc: 0.9877\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0435 - acc: 0.9915\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.0421 - acc: 0.9915\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048, score=0.000, total= 4.1min\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 5.2716 - acc: 0.0246\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 1.2067 - acc: 0.7545\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.6181 - acc: 0.8860\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.5076 - acc: 0.9205\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.4381 - acc: 0.9149\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.3559 - acc: 0.9309\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.3056 - acc: 0.9451\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2768 - acc: 0.9513\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2447 - acc: 0.9518\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.2088 - acc: 0.9584\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1718 - acc: 0.9721\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1632 - acc: 0.9626\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1241 - acc: 0.9740\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1241 - acc: 0.9721\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1431 - acc: 0.9683\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 14s 7ms/step - loss: 0.1258 - acc: 0.9711\n",
      "1057/1057 [==============================] - 5s 4ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=2048, decay=1e-09, batch_size=2048, score=0.004, total= 4.2min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 21s 10ms/step - loss: 3.9740 - acc: 0.2465\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.6196 - acc: 0.8832\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.2859 - acc: 0.9518\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.1614 - acc: 0.9773\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0949 - acc: 0.9830\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0931 - acc: 0.9849\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0678 - acc: 0.9896\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0412 - acc: 0.9943\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0302 - acc: 0.9953\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0213 - acc: 0.9957\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0126 - acc: 0.9991\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0153 - acc: 0.9976\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0156 - acc: 0.9957\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0065 - acc: 0.9995\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0035 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024, score=0.004, total= 3.0min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 22s 11ms/step - loss: 3.8465 - acc: 0.2848\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.5340 - acc: 0.8865\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.2269 - acc: 0.9536\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.1223 - acc: 0.9745\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0662 - acc: 0.9896\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0586 - acc: 0.9886\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0352 - acc: 0.9948\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9972\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0139 - acc: 0.9976\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0128 - acc: 0.9981\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0083 - acc: 0.9991\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0270 - acc: 0.9929\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0088 - acc: 0.9986\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0069 - acc: 0.9981\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0048 - acc: 0.9995\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024, score=0.000, total= 3.1min\n",
      "[CV] output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 22s 10ms/step - loss: 4.0741 - acc: 0.2214\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.6902 - acc: 0.8605\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.3699 - acc: 0.9309\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.2001 - acc: 0.9683\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.1614 - acc: 0.9716\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.1182 - acc: 0.9773\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0969 - acc: 0.9816\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0555 - acc: 0.9915\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0280 - acc: 0.9962\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0325 - acc: 0.9920\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0345 - acc: 0.9929\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0772 - acc: 0.9853\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0238 - acc: 0.9953\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0193 - acc: 0.9948\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0119 - acc: 0.9976\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0074 - acc: 0.9995\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=0, batch_size=1024, score=0.004, total= 3.1min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 23s 11ms/step - loss: 3.9313 - acc: 0.2412\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.8741 - acc: 0.8434\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.4583 - acc: 0.9347\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.2982 - acc: 0.9574\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1790 - acc: 0.9820\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1211 - acc: 0.9877\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0840 - acc: 0.9934\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0627 - acc: 0.9957\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0433 - acc: 0.9976\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0440 - acc: 0.9948\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0310 - acc: 0.9976\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0205 - acc: 0.9991\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9995\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0205 - acc: 0.9967\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0137 - acc: 0.9995\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0099 - acc: 1.0000\n",
      "1057/1057 [==============================] - 5s 4ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024, score=0.005, total= 3.2min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 24s 11ms/step - loss: 3.8243 - acc: 0.2706\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.8455 - acc: 0.8392\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.4322 - acc: 0.9361\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.2995 - acc: 0.9612\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1882 - acc: 0.9730\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.1204 - acc: 0.9830\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0777 - acc: 0.9924\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0705 - acc: 0.9882\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0529 - acc: 0.9934\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0353 - acc: 0.9976\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 10s 5ms/step - loss: 0.0233 - acc: 0.9981\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0164 - acc: 0.9995\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0098 - acc: 1.0000\n",
      "1057/1057 [==============================] - 5s 4ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024, score=0.001, total= 3.2min\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 24s 11ms/step - loss: 4.0176 - acc: 0.2237\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.9999 - acc: 0.8344\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.6238 - acc: 0.9125\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.3987 - acc: 0.9475\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.2559 - acc: 0.9716\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1881 - acc: 0.9778\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.1298 - acc: 0.9849\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0893 - acc: 0.9872\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0650 - acc: 0.9929\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0482 - acc: 0.9981\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0347 - acc: 0.9991\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0298 - acc: 0.9976\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0298 - acc: 0.9957\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0202 - acc: 0.9991\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 0.0122 - acc: 1.0000\n",
      "1057/1057 [==============================] - 4s 4ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=2048, decay=1e-06, batch_size=1024, score=0.004, total= 3.2min\n",
      "[CV] output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 57s 27ms/step - loss: 5.4007 - acc: 0.0208\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.3375 - acc: 0.9522\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.1643 - acc: 0.9801\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.1260 - acc: 0.9934\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0914 - acc: 0.9962\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0661 - acc: 0.9972\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0560 - acc: 0.9981\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0495 - acc: 0.9967\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0396 - acc: 0.9976\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0292 - acc: 0.9986\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 14/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0100 - acc: 1.0000\n",
      "1057/1057 [==============================] - 6s 6ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048, score=0.003, total= 8.0min\n",
      "[CV] output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 59s 28ms/step - loss: 5.3519 - acc: 0.0260\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.3198 - acc: 0.9565\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.1662 - acc: 0.9839\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.1029 - acc: 0.9957\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0702 - acc: 0.9995\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0520 - acc: 0.9991\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 0.0409 - acc: 0.9991\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 30s 14ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0176 - acc: 0.9995\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0151 - acc: 0.9995\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0127 - acc: 0.9995\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0079 - acc: 1.0000\n",
      "1057/1057 [==============================] - 7s 6ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048, score=0.000, total= 8.2min\n",
      "[CV] output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048 \n",
      "Epoch 1/16\n",
      "2114/2114 [==============================] - 63s 30ms/step - loss: 5.3156 - acc: 0.0232\n",
      "Epoch 2/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.3467 - acc: 0.9551\n",
      "Epoch 3/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 0.1780 - acc: 0.9844\n",
      "Epoch 4/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.1311 - acc: 0.9910\n",
      "Epoch 5/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.1001 - acc: 0.9957\n",
      "Epoch 6/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0750 - acc: 0.9981\n",
      "Epoch 7/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0608 - acc: 0.9986\n",
      "Epoch 8/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0530 - acc: 0.9986\n",
      "Epoch 9/16\n",
      "2114/2114 [==============================] - 29s 14ms/step - loss: 0.0438 - acc: 0.9995\n",
      "Epoch 10/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0348 - acc: 0.9995\n",
      "Epoch 11/16\n",
      "2114/2114 [==============================] - 27s 13ms/step - loss: 0.0294 - acc: 0.9995\n",
      "Epoch 12/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0284 - acc: 0.9981\n",
      "Epoch 13/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0244 - acc: 0.9986\n",
      "Epoch 14/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0181 - acc: 0.9995\n",
      "Epoch 15/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0126 - acc: 1.0000\n",
      "1057/1057 [==============================] - 7s 7ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=1024, nn1=4096, lr=0.0001, input_shape=7, decay=0, batch_size=2048, score=0.004, total= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 136.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "3171/3171 [==============================] - 29s 9ms/step - loss: 4.2111 - acc: 0.1583\n",
      "Epoch 2/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.8028 - acc: 0.9313\n",
      "Epoch 3/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.3614 - acc: 0.9845\n",
      "Epoch 4/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.1857 - acc: 0.9981\n",
      "Epoch 5/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.1124 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0762 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0550 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "3171/3171 [==============================] - 14s 5ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "3171/3171 [==============================] - 14s 4ms/step - loss: 0.0134 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(train_data, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(grid_result.cv_results_)\n",
    "cv_results_df.to_csv('gridsearch_Inception.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_output_shape</th>\n",
       "      <th>param_nn3</th>\n",
       "      <th>param_nn2</th>\n",
       "      <th>param_nn1</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_input_shape</th>\n",
       "      <th>param_decay</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>565.142282</td>\n",
       "      <td>7.540171</td>\n",
       "      <td>4.024790</td>\n",
       "      <td>0.160267</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 512, ...</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.752007</td>\n",
       "      <td>0.786410</td>\n",
       "      <td>2.097494</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 512, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.735591</td>\n",
       "      <td>0.652292</td>\n",
       "      <td>3.001509</td>\n",
       "      <td>0.103047</td>\n",
       "      <td>101</td>\n",
       "      <td>1000</td>\n",
       "      <td>1024</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 1000, 'nn2': 1024...</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.918611</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>3.462500</td>\n",
       "      <td>0.448275</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2048</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 2048,...</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302.510548</td>\n",
       "      <td>3.925874</td>\n",
       "      <td>4.025182</td>\n",
       "      <td>0.670291</td>\n",
       "      <td>101</td>\n",
       "      <td>1000</td>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2048</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 1000, 'nn2': 512,...</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128.716579</td>\n",
       "      <td>0.950203</td>\n",
       "      <td>3.549498</td>\n",
       "      <td>0.371872</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>2048</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 2048,...</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227.970891</td>\n",
       "      <td>20.574100</td>\n",
       "      <td>4.292315</td>\n",
       "      <td>0.274153</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2048</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 2048,...</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180.298902</td>\n",
       "      <td>1.525775</td>\n",
       "      <td>4.206313</td>\n",
       "      <td>0.230874</td>\n",
       "      <td>101</td>\n",
       "      <td>1000</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 1000, 'nn2': 512,...</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>186.447254</td>\n",
       "      <td>0.599672</td>\n",
       "      <td>4.549720</td>\n",
       "      <td>0.076046</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>2048</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2048</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 2048,...</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>481.641443</td>\n",
       "      <td>3.385018</td>\n",
       "      <td>6.589171</td>\n",
       "      <td>0.435379</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 1024,...</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     565.142282      7.540171         4.024790        0.160267   \n",
       "1      99.752007      0.786410         2.097494        0.036809   \n",
       "2     300.735591      0.652292         3.001509        0.103047   \n",
       "3     220.918611      0.898483         3.462500        0.448275   \n",
       "4     302.510548      3.925874         4.025182        0.670291   \n",
       "5     128.716579      0.950203         3.549498        0.371872   \n",
       "6     227.970891     20.574100         4.292315        0.274153   \n",
       "7     180.298902      1.525775         4.206313        0.230874   \n",
       "8     186.447254      0.599672         4.549720        0.076046   \n",
       "9     481.641443      3.385018         6.589171        0.435379   \n",
       "\n",
       "  param_output_shape param_nn3 param_nn2 param_nn1 param_lr param_input_shape  \\\n",
       "0                101       500       512      4096   0.0001              2048   \n",
       "1                101       200       512      1024     0.01                 7   \n",
       "2                101      1000      1024      2048   0.0001                 7   \n",
       "3                101       500      2048      2048    0.001              2048   \n",
       "4                101      1000       512      2048   0.0001              2048   \n",
       "5                101       200      2048      1024   0.0001                 7   \n",
       "6                101       500      2048      2048    0.001              2048   \n",
       "7                101      1000       512      1024    0.001                 7   \n",
       "8                101       200      2048      1024    0.001              2048   \n",
       "9                101       500      1024      4096   0.0001                 7   \n",
       "\n",
       "  param_decay param_batch_size  \\\n",
       "0           0              512   \n",
       "1           0             2048   \n",
       "2       1e-09              512   \n",
       "3       1e-09             1024   \n",
       "4       1e-06              512   \n",
       "5           0             1024   \n",
       "6       1e-09             2048   \n",
       "7           0             1024   \n",
       "8       1e-06             1024   \n",
       "9           0             2048   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'output_shape': 101, 'nn3': 500, 'nn2': 512, ...           0.000946   \n",
       "1  {'output_shape': 101, 'nn3': 200, 'nn2': 512, ...           0.000000   \n",
       "2  {'output_shape': 101, 'nn3': 1000, 'nn2': 1024...           0.003784   \n",
       "3  {'output_shape': 101, 'nn3': 500, 'nn2': 2048,...           0.000946   \n",
       "4  {'output_shape': 101, 'nn3': 1000, 'nn2': 512,...           0.003784   \n",
       "5  {'output_shape': 101, 'nn3': 200, 'nn2': 2048,...           0.006623   \n",
       "6  {'output_shape': 101, 'nn3': 500, 'nn2': 2048,...           0.002838   \n",
       "7  {'output_shape': 101, 'nn3': 1000, 'nn2': 512,...           0.003784   \n",
       "8  {'output_shape': 101, 'nn3': 200, 'nn2': 2048,...           0.004730   \n",
       "9  {'output_shape': 101, 'nn3': 500, 'nn2': 1024,...           0.002838   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.000946           0.003784         0.001892        0.001338   \n",
       "1           0.001892           0.002838         0.001577        0.001180   \n",
       "2           0.000000           0.003784         0.002523        0.001784   \n",
       "3           0.000000           0.003784         0.001577        0.001608   \n",
       "4           0.003784           0.005676         0.004415        0.000892   \n",
       "5           0.002838           0.006623         0.005361        0.001784   \n",
       "6           0.000000           0.003784         0.002208        0.001608   \n",
       "7           0.000000           0.003784         0.002523        0.001784   \n",
       "8           0.000946           0.003784         0.003154        0.001608   \n",
       "9           0.000000           0.003784         0.002208        0.001608   \n",
       "\n",
       "   rank_test_score  \n",
       "0                8  \n",
       "1               10  \n",
       "2                4  \n",
       "3                9  \n",
       "4                2  \n",
       "5                1  \n",
       "6                6  \n",
       "7                4  \n",
       "8                3  \n",
       "9                6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_shape': 101,\n",
       " 'nn3': 200,\n",
       " 'nn2': 2048,\n",
       " 'nn1': 1024,\n",
       " 'lr': 0.0001,\n",
       " 'input_shape': 7,\n",
       " 'decay': 0,\n",
       " 'batch_size': 1024}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters after RandomizedSearchCV\n",
    "\n",
    "nn1 = 1024; nn2 = 1024; nn3 = 200\n",
    "lr = 0.0001; decay=0\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularzation Parameters\n",
    "\n",
    "dropout = 0.5\n",
    "l1 = 0.0001\n",
    "l2 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nn1, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn2, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn3, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "            \n",
    "    model.add(Dense(NB_CLASSES, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_onehot = to_categorical(train_labels, NB_CLASSES)            #One Hot Encoder\n",
    "validation_labels_onehot = to_categorical(validation_labels, NB_CLASSES)  #One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 307 samples, validate on 74 samples\n",
      "Epoch 1/32\n",
      "307/307 [==============================] - 26s 85ms/step - loss: 46.4672 - acc: 0.0879 - val_loss: 45.0449 - val_acc: 0.5405\n",
      "Epoch 2/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 45.6175 - acc: 0.2248 - val_loss: 44.4285 - val_acc: 0.7838\n",
      "Epoch 3/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 44.8443 - acc: 0.4397 - val_loss: 44.0006 - val_acc: 0.8649\n",
      "Epoch 4/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 44.4915 - acc: 0.4495 - val_loss: 43.6444 - val_acc: 0.9054\n",
      "Epoch 5/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 44.0419 - acc: 0.5635 - val_loss: 43.3404 - val_acc: 0.9054\n",
      "Epoch 6/32\n",
      "307/307 [==============================] - 4s 11ms/step - loss: 43.7606 - acc: 0.6352 - val_loss: 43.0652 - val_acc: 0.9054\n",
      "Epoch 7/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 43.4715 - acc: 0.6743 - val_loss: 42.7989 - val_acc: 0.9189\n",
      "Epoch 8/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 43.1768 - acc: 0.7231 - val_loss: 42.5457 - val_acc: 0.9189\n",
      "Epoch 9/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 42.8413 - acc: 0.7720 - val_loss: 42.2950 - val_acc: 0.9189\n",
      "Epoch 10/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 42.6306 - acc: 0.7622 - val_loss: 42.0473 - val_acc: 0.9054\n",
      "Epoch 11/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 42.3249 - acc: 0.8111 - val_loss: 41.8015 - val_acc: 0.9054\n",
      "Epoch 12/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 42.0790 - acc: 0.8404 - val_loss: 41.5518 - val_acc: 0.9054\n",
      "Epoch 13/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 41.7993 - acc: 0.8469 - val_loss: 41.2999 - val_acc: 0.9054\n",
      "Epoch 14/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 41.4758 - acc: 0.8730 - val_loss: 41.0457 - val_acc: 0.9324\n",
      "Epoch 15/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 41.3156 - acc: 0.8306 - val_loss: 40.7877 - val_acc: 0.9324\n",
      "Epoch 16/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 40.9388 - acc: 0.8925 - val_loss: 40.5272 - val_acc: 0.9324\n",
      "Epoch 17/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 40.6366 - acc: 0.9088 - val_loss: 40.2652 - val_acc: 0.9324\n",
      "Epoch 18/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 40.4597 - acc: 0.8567 - val_loss: 40.0016 - val_acc: 0.9324\n",
      "Epoch 19/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 40.1083 - acc: 0.9121 - val_loss: 39.7353 - val_acc: 0.9324\n",
      "Epoch 20/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 39.8566 - acc: 0.9153 - val_loss: 39.4675 - val_acc: 0.9324\n",
      "Epoch 21/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 39.5797 - acc: 0.9121 - val_loss: 39.1979 - val_acc: 0.9324\n",
      "Epoch 22/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 39.2739 - acc: 0.9316 - val_loss: 38.9267 - val_acc: 0.9324\n",
      "Epoch 23/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 38.9827 - acc: 0.9446 - val_loss: 38.6537 - val_acc: 0.9459\n",
      "Epoch 24/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 38.7320 - acc: 0.9349 - val_loss: 38.3784 - val_acc: 0.9324\n",
      "Epoch 25/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 38.3996 - acc: 0.9707 - val_loss: 38.1026 - val_acc: 0.9324\n",
      "Epoch 26/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 38.1347 - acc: 0.9544 - val_loss: 37.8253 - val_acc: 0.9459\n",
      "Epoch 27/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 37.8342 - acc: 0.9674 - val_loss: 37.5463 - val_acc: 0.9459\n",
      "Epoch 28/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 37.5895 - acc: 0.9642 - val_loss: 37.2661 - val_acc: 0.9595\n",
      "Epoch 29/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 37.2714 - acc: 0.9772 - val_loss: 36.9848 - val_acc: 0.9595\n",
      "Epoch 30/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 36.9822 - acc: 0.9642 - val_loss: 36.7026 - val_acc: 0.9595\n",
      "Epoch 31/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 36.6884 - acc: 0.9805 - val_loss: 36.4191 - val_acc: 0.9595\n",
      "Epoch 32/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 36.4185 - acc: 0.9674 - val_loss: 36.1359 - val_acc: 0.9595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ff07cf5f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.fit(train_data, train_labels_onehot,\n",
    "              epochs=32,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.save_weights(top_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_model():\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                 \n",
    "    base = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "    \n",
    "    top = Sequential()\n",
    "\n",
    "    top.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    top.add(Dense(nn1, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())\n",
    "    top.add(Dense(nn2, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())\n",
    "    top.add(Dense(nn3, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())            \n",
    "    top.add(Dense(NB_CLASSES, activation='softmax'))\n",
    "    top.load_weights(top_weights_file)\n",
    "    top.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    \n",
    "    \n",
    "    model = Model(input= base.input, output= top(base.output))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 56, 56, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 56, 56, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 56, 56, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 11)           104027275   activation_98[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 127,614,987\n",
      "Trainable params: 0\n",
      "Non-trainable params: 127,614,987\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = complete_model()\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "print(\"Model Summary\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 11 classes.\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "            test_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=len(test_labels),\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "test_predictions = model.predict_generator(generator, 1, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.asarray(list(map(str,np.argmax(test_predictions,axis=1)))).reshape(-1,1)\n",
    "test_labels = np.asarray(test_labels).reshape(-1,1)\n",
    "test_acc, test_acc_op = tf.metrics.accuracy(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = sess.run(test_acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy : 0.9444444\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest accuracy : ' + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
