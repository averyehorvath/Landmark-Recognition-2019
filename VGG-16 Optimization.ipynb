{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 : Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications, Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'Data/Training_Data'\n",
    "validation_data_dir = 'Data/Validation_Data'\n",
    "test_data_dir= 'Data/Test_Data'\n",
    "\n",
    "training_features_file = 'Features/training_features_VGG16.npy'\n",
    "validation_features_file = 'Features/validation_features_VGG16.npy'\n",
    "top_weights_file = 'Weights/weights_VGG16.h5'\n",
    "model_file = 'Models/model_vgg16.h5'\n",
    "\n",
    "train_labels_file = 'Labels/training_labels.npy'\n",
    "validation_labels_file = 'Labels/validation_labels.npy'\n",
    "test_labels_file = 'Labels/test_labels.npy'\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "NB_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(open(train_labels_file, 'rb'))\n",
    "validation_labels = np.load(open(validation_labels_file, 'rb'))\n",
    "test_labels = np.load(open(test_labels_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : 307 Images\n",
      "Validation Data : 74 Images\n",
      "Test Data : 18 Images\n"
     ]
    }
   ],
   "source": [
    "print('Training Data : ' + str(len(train_labels)) + ' Images')\n",
    "print('Validation Data : ' + str(len(validation_labels)) + ' Images')\n",
    "print('Test Data : ' + str(len(test_labels)) + ' Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to feature vectors using weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_feature_vectors(model, directory, batch_size, steps):\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False) # Keep the data in the same order\n",
    "    \n",
    "    features = model.predict_generator(generator, steps, verbose=1) \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 55s 179ms/step\n",
      "Found 74 images belonging to 11 classes.\n",
      "74/74 [==============================] - 12s 159ms/step\n"
     ]
    }
   ],
   "source": [
    "# Batch size has to be a multiple of the number of images  to keep our vectors consistents\n",
    "training_batch_size = 1 # batch size for feature pre-training\n",
    "validation_batch_size = 1 # batch size for feature pre-training\n",
    "\n",
    "base_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3)) #VGG16 trained on imagenet\n",
    "training_features = images_to_feature_vectors(base_model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(base_model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_features_file, 'wb') as file:\n",
    "        np.save(file, training_features, allow_pickle = False)\n",
    "with open(validation_features_file, 'wb') as file:\n",
    "        np.save(file, validation_features, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search CV training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr, decay, nn1, nn2, nn3, input_shape, output_shape):\n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture'''\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=lr, decay=decay)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nn1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "            \n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate values\n",
    "lr=[1e-2, 1e-3, 1e-4]\n",
    "decay=[1e-6,1e-9,0]\n",
    "\n",
    "# Number of neurons per layer\n",
    "nn1=[4096,2048,1024]\n",
    "nn2=[2048,1024,512]\n",
    "nn3=[1000,500,200]\n",
    "\n",
    "batch_size=[2048,1024,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open(training_features_file, 'rb'))\n",
    "#train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "validation_data = np.load(open(validation_features_file, 'rb'))\n",
    "#validation_data = validation_data.reshape(validation_data.shape[0],-1)\n",
    "    \n",
    "train_labels_onehot = to_categorical(train_labels,NB_CLASSES)            #One Hot Encoder\n",
    "validation_labels_onehot = to_categorical(validation_labels,NB_CLASSES)  #One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary summary\n",
    "param_grid = dict(\n",
    "                    lr=lr, decay=decay, nn1=nn1, nn2=nn2, nn3=nn3,\n",
    "                    batch_size=batch_size,\n",
    "                    input_shape=train_data.shape[1:], output_shape = (NB_CLASSES,)\n",
    "                 )\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, cv=KFold(3), param_distributions=param_grid, \n",
    "                          verbose=20,  n_iter=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 5s 27ms/step - loss: 5.4665 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 9.6188e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 7.9229e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 6.6449e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 5.6679e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 4.9042e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 4.2975e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 3.8071e-04 - acc: 1.0000\n",
      "103/103 [==============================] - 1s 6ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048, score=0.194, total=  31.8s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   31.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 8s 38ms/step - loss: 5.3803 - acc: 0.0195\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 8.0083e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 6.3142e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 5.1540e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 4.3202e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 3.7012e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 3.2260e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 2.8517e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 2.5493e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 2.2997e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 6ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048, score=0.196, total=  33.3s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 8s 38ms/step - loss: 5.4778 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1132 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 8.9475e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 7.3087e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 6.1191e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 5.2254e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 4.5343e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 3.9879e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 3.5462e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 3.1836e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 8ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-06, batch_size=2048, score=0.078, total=  33.5s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 4s 18ms/step - loss: 5.3700 - acc: 0.0000e+00\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.3168 - acc: 0.9853\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
      "103/103 [==============================] - 1s 6ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024, score=0.146, total=  13.4s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 4s 19ms/step - loss: 5.0677 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3126 - acc: 0.9902\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 8ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024, score=0.206, total=  13.2s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 4s 19ms/step - loss: 5.2002 - acc: 0.0146\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3469 - acc: 0.9854\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 9ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.001, input_shape=7, decay=1e-09, batch_size=1024, score=0.078, total=  13.7s\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 6s 29ms/step - loss: 5.4991 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 9.9956e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 7.1736e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 5.5173e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 4.4321e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 3.6666e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 3.1015e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 2.6726e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 2.3380e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 2.0697e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 1s 5ms/step - loss: 1.8515e-04 - acc: 1.0000\n",
      "103/103 [==============================] - 1s 10ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024, score=0.155, total=  22.0s\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 6s 30ms/step - loss: 5.0847 - acc: 0.0195\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0501 - acc: 0.9902\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0127 - acc: 0.9951\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 8.8542e-04 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 6.3556e-04 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 4.8958e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 3.9550e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 3.2980e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.7997e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.4064e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.0916e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 1.8391e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 1.6361e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 1.4719e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 11ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024, score=0.147, total=  22.5s\n",
      "[CV] output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 6s 31ms/step - loss: 5.6465 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0343 - acc: 0.9951\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 8.2091e-04 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 6.8052e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 5.6962e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 4.7994e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 4.0644e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 3.4568e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.9571e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.5474e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 2.2114e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 12ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=2048, nn1=2048, lr=0.001, input_shape=512, decay=0, batch_size=1024, score=0.069, total=  22.6s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 5s 24ms/step - loss: 5.2158 - acc: 0.0147\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.2091 - acc: 0.9853\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 8.2694e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 6.7708e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 5.6739e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 4.8413e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 4.1883e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 3.6657e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 3.2400e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 2.8871e-04 - acc: 1.0000\n",
      "103/103 [==============================] - 1s 14ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512, score=0.155, total=  14.4s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 5s 26ms/step - loss: 5.5561 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1980 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 7.7118e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.0293e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.8765e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.0559e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4507e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9926e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.6368e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.3540e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 13ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512, score=0.137, total=  15.1s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 6s 28ms/step - loss: 5.5424 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1674 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.7271e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.8557e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.5407e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.5867e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8747e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3287e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9014e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.5606e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 1s 15ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.001, input_shape=7, decay=1e-06, batch_size=512, score=0.088, total=  16.0s\n",
      "[CV] output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 6s 30ms/step - loss: 5.0924 - acc: 0.0245\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.6515 - acc: 0.8824\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.5701 - acc: 0.9902\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.1420 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0929 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0536 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0205 - acc: 1.0000\n",
      "103/103 [==============================] - 2s 15ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048, score=0.223, total=  16.0s\n",
      "[CV] output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  4.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 6s 30ms/step - loss: 5.3972 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 1.5590 - acc: 0.8829\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.4679 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1964 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1087 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0728 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0176 - acc: 1.0000\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048, score=0.098, total=  16.7s\n",
      "[CV] output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  4.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 8s 37ms/step - loss: 5.1377 - acc: 0.0195\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 1.5666 - acc: 0.8878\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.5441 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1294 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0838 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0185 - acc: 1.0000\n",
      "102/102 [==============================] - 2s 17ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=1024, nn1=1024, lr=0.0001, input_shape=512, decay=0, batch_size=2048, score=0.078, total=  18.1s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 7s 33ms/step - loss: 5.4309 - acc: 0.0196\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.4116 - acc: 0.9020\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.3218 - acc: 0.9951\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0048 - acc: 1.0000\n",
      "103/103 [==============================] - 2s 18ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.194, total=  17.7s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 7s 32ms/step - loss: 5.3776 - acc: 0.0146\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 1.3221 - acc: 0.8927\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.2776 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0855 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 1.0000\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.157, total=  16.9s\n",
      "[CV] output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 7s 34ms/step - loss: 5.3467 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 1.3921 - acc: 0.9073\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3554 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
      "102/102 [==============================] - 2s 21ms/step\n",
      "[CV]  output_shape=101, nn3=500, nn2=512, nn1=1024, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.069, total=  17.7s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "204/204 [==============================] - 9s 45ms/step - loss: 5.2046 - acc: 0.0147\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.9143 - acc: 0.9853\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.2054 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 0.0109 - acc: 1.0000\n",
      "103/103 [==============================] - 2s 23ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.107, total=  26.4s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  6.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "205/205 [==============================] - 9s 45ms/step - loss: 5.1331 - acc: 0.0146\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.7881 - acc: 0.9902\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.1757 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0102 - acc: 1.0000\n",
      "102/102 [==============================] - 3s 26ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.118, total=  26.4s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 9s 46ms/step - loss: 5.2726 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 1.0965 - acc: 0.9512\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.3233 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.1401 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.0169 - acc: 1.0000\n",
      "102/102 [==============================] - 3s 26ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=2048, lr=0.0001, input_shape=7, decay=1e-06, batch_size=512, score=0.088, total=  27.5s\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048 \n",
      "Epoch 1/16\n",
      "204/204 [==============================] - 12s 60ms/step - loss: 5.1468 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.3790 - acc: 0.9853\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.0742 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 2s 7ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0033 - acc: 1.0000\n",
      "103/103 [==============================] - 3s 27ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048, score=0.194, total=  39.9s\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 13s 61ms/step - loss: 5.2783 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.3639 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0028 - acc: 1.0000\n",
      "102/102 [==============================] - 3s 29ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048, score=0.216, total=  40.7s\n",
      "[CV] output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 13s 61ms/step - loss: 5.1872 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.3858 - acc: 1.0000\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0705 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0062 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.0029 - acc: 1.0000\n",
      "102/102 [==============================] - 4s 34ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=512, nn1=4096, lr=0.001, input_shape=7, decay=1e-09, batch_size=2048, score=0.088, total=  40.9s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512 \n",
      "Epoch 1/16\n",
      "204/204 [==============================] - 9s 45ms/step - loss: 5.3777 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.4885 - acc: 0.9020\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.1508 - acc: 0.9608\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.9951\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0262 - acc: 0.9951\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 9.0251e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 7.9180e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 6.8420e-04 - acc: 1.0000\n",
      "103/103 [==============================] - 3s 29ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512, score=0.223, total=  20.9s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 10s 47ms/step - loss: 5.1737 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6900 - acc: 0.8732\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.9220\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 9.5567e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 3s 31ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512, score=0.176, total=  21.6s\n",
      "[CV] output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 10s 48ms/step - loss: 5.2579 - acc: 0.0195\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.5686 - acc: 0.8878\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.2583 - acc: 0.9415\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.9902\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.9854\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.6949e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 7.2327e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.2434e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.5275e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.9803e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 3s 30ms/step\n",
      "[CV]  output_shape=101, nn3=200, nn2=2048, nn1=1024, lr=0.01, input_shape=7, decay=1e-06, batch_size=512, score=0.088, total=  22.7s\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n",
      "204/204 [==============================] - 15s 74ms/step - loss: 5.5174 - acc: 0.0049\n",
      "Epoch 2/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.4871 - acc: 0.9020\n",
      "Epoch 3/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 2.4260 - acc: 0.7157\n",
      "Epoch 4/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.3993 - acc: 0.9265\n",
      "Epoch 5/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0768 - acc: 0.9706\n",
      "Epoch 6/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0626 - acc: 0.9853\n",
      "Epoch 7/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0213 - acc: 0.9951\n",
      "Epoch 8/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0140 - acc: 0.9951\n",
      "Epoch 9/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "204/204 [==============================] - 2s 8ms/step - loss: 0.0023 - acc: 1.0000\n",
      "103/103 [==============================] - 4s 35ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024, score=0.058, total=  44.9s\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 14s 71ms/step - loss: 5.4931 - acc: 0.0098\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.4800 - acc: 0.8976\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 2.2132 - acc: 0.7805\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0476 - acc: 0.9854\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0623 - acc: 0.9805\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0389 - acc: 0.9902\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0092 - acc: 0.9951\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 5.0820e-04 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 2.5932e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 2.0105e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.7743e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.6098e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.4662e-04 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.3349e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.2156e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 4s 37ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024, score=0.078, total=  44.5s\n",
      "[CV] output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024 \n",
      "Epoch 1/16\n",
      "205/205 [==============================] - 15s 72ms/step - loss: 5.6636 - acc: 0.0000e+00\n",
      "Epoch 2/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.2505 - acc: 0.9268\n",
      "Epoch 3/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.8588 - acc: 0.8537\n",
      "Epoch 4/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.1268 - acc: 0.8976\n",
      "Epoch 5/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.3395 - acc: 0.9463\n",
      "Epoch 6/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0348 - acc: 0.9951\n",
      "Epoch 7/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1951 - acc: 0.9561\n",
      "Epoch 8/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.1180 - acc: 0.9805\n",
      "Epoch 9/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.0345 - acc: 0.9902\n",
      "Epoch 10/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 4.0350e-04 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 1.6212e-04 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.2591e-04 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.0562e-04 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 9.5516e-05 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.0675e-04 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 1.5298e-04 - acc: 1.0000\n",
      "102/102 [==============================] - 4s 38ms/step\n",
      "[CV]  output_shape=101, nn3=1000, nn2=1024, nn1=4096, lr=0.01, input_shape=7, decay=0, batch_size=1024, score=0.020, total=  44.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 12.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "307/307 [==============================] - 16s 52ms/step - loss: 5.2574 - acc: 0.0065\n",
      "Epoch 2/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.3385 - acc: 0.9967\n",
      "Epoch 3/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0658 - acc: 1.0000\n",
      "Epoch 4/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 5/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 6/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 7/16\n",
      "307/307 [==============================] - 2s 7ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 8/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 9/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 10/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 11/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 12/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 13/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 14/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 15/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 16/16\n",
      "307/307 [==============================] - 2s 5ms/step - loss: 0.0029 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(train_data, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(grid_result.cv_results_)\n",
    "cv_results_df.to_csv('gridsearch_VGG16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_output_shape</th>\n",
       "      <th>param_nn3</th>\n",
       "      <th>param_nn2</th>\n",
       "      <th>param_nn1</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_input_shape</th>\n",
       "      <th>param_decay</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.193858</td>\n",
       "      <td>0.675317</td>\n",
       "      <td>0.670147</td>\n",
       "      <td>0.076867</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 512, ...</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.629730</td>\n",
       "      <td>0.166648</td>\n",
       "      <td>0.787965</td>\n",
       "      <td>0.101065</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>2048</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 2048,...</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.143322</td>\n",
       "      <td>0.051973</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.232271</td>\n",
       "      <td>0.211854</td>\n",
       "      <td>1.140251</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 2048,...</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.123779</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.733493</td>\n",
       "      <td>0.649357</td>\n",
       "      <td>1.433798</td>\n",
       "      <td>0.045567</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 512, ...</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.127036</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.167023</td>\n",
       "      <td>0.837273</td>\n",
       "      <td>1.776417</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 1024,...</td>\n",
       "      <td>0.223301</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.133550</td>\n",
       "      <td>0.064272</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.392101</td>\n",
       "      <td>0.376280</td>\n",
       "      <td>2.017972</td>\n",
       "      <td>0.104266</td>\n",
       "      <td>101</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 500, 'nn2': 512, ...</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.140065</td>\n",
       "      <td>0.052646</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.241458</td>\n",
       "      <td>0.439833</td>\n",
       "      <td>2.522223</td>\n",
       "      <td>0.129908</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 2048,...</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.104235</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.399706</td>\n",
       "      <td>0.248150</td>\n",
       "      <td>3.070402</td>\n",
       "      <td>0.320667</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>2048</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 512, ...</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.641577</td>\n",
       "      <td>0.694909</td>\n",
       "      <td>3.087179</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>2048</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>512</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 200, 'nn2': 2048,...</td>\n",
       "      <td>0.223301</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>0.056013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41.043226</td>\n",
       "      <td>0.227881</td>\n",
       "      <td>3.717691</td>\n",
       "      <td>0.116954</td>\n",
       "      <td>101</td>\n",
       "      <td>1000</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'output_shape': 101, 'nn3': 1000, 'nn2': 1024...</td>\n",
       "      <td>0.058252</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.024369</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      32.193858      0.675317         0.670147        0.076867   \n",
       "1      12.629730      0.166648         0.787965        0.101065   \n",
       "2      21.232271      0.211854         1.140251        0.074460   \n",
       "3      13.733493      0.649357         1.433798        0.045567   \n",
       "4      15.167023      0.837273         1.776417        0.202147   \n",
       "5      15.392101      0.376280         2.017972        0.104266   \n",
       "6      24.241458      0.439833         2.522223        0.129908   \n",
       "7      37.399706      0.248150         3.070402        0.320667   \n",
       "8      18.641577      0.694909         3.087179        0.062845   \n",
       "9      41.043226      0.227881         3.717691        0.116954   \n",
       "\n",
       "  param_output_shape param_nn3 param_nn2 param_nn1 param_lr param_input_shape  \\\n",
       "0                101       500       512      4096    0.001                 7   \n",
       "1                101       200      2048      1024    0.001                 7   \n",
       "2                101       500      2048      2048    0.001               512   \n",
       "3                101       500       512      1024    0.001                 7   \n",
       "4                101       200      1024      1024   0.0001               512   \n",
       "5                101       500       512      1024   0.0001                 7   \n",
       "6                101       200      2048      2048   0.0001                 7   \n",
       "7                101       200       512      4096    0.001                 7   \n",
       "8                101       200      2048      1024     0.01                 7   \n",
       "9                101      1000      1024      4096     0.01                 7   \n",
       "\n",
       "  param_decay param_batch_size  \\\n",
       "0       1e-06             2048   \n",
       "1       1e-09             1024   \n",
       "2           0             1024   \n",
       "3       1e-06              512   \n",
       "4           0             2048   \n",
       "5       1e-06              512   \n",
       "6       1e-06              512   \n",
       "7       1e-09             2048   \n",
       "8       1e-06              512   \n",
       "9           0             1024   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'output_shape': 101, 'nn3': 500, 'nn2': 512, ...           0.194175   \n",
       "1  {'output_shape': 101, 'nn3': 200, 'nn2': 2048,...           0.145631   \n",
       "2  {'output_shape': 101, 'nn3': 500, 'nn2': 2048,...           0.155340   \n",
       "3  {'output_shape': 101, 'nn3': 500, 'nn2': 512, ...           0.155340   \n",
       "4  {'output_shape': 101, 'nn3': 200, 'nn2': 1024,...           0.223301   \n",
       "5  {'output_shape': 101, 'nn3': 500, 'nn2': 512, ...           0.194175   \n",
       "6  {'output_shape': 101, 'nn3': 200, 'nn2': 2048,...           0.106796   \n",
       "7  {'output_shape': 101, 'nn3': 200, 'nn2': 512, ...           0.194175   \n",
       "8  {'output_shape': 101, 'nn3': 200, 'nn2': 2048,...           0.223301   \n",
       "9  {'output_shape': 101, 'nn3': 1000, 'nn2': 1024...           0.058252   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.196078           0.078431         0.156352        0.054969   \n",
       "1           0.205882           0.078431         0.143322        0.051973   \n",
       "2           0.147059           0.068627         0.123779        0.039049   \n",
       "3           0.137255           0.088235         0.127036        0.028349   \n",
       "4           0.098039           0.078431         0.133550        0.064272   \n",
       "5           0.156863           0.068627         0.140065        0.052646   \n",
       "6           0.117647           0.088235         0.104235        0.012125   \n",
       "7           0.215686           0.088235         0.166124        0.055640   \n",
       "8           0.176471           0.088235         0.162866        0.056013   \n",
       "9           0.078431           0.019608         0.052117        0.024369   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                4  \n",
       "2                8  \n",
       "3                7  \n",
       "4                6  \n",
       "5                5  \n",
       "6                9  \n",
       "7                1  \n",
       "8                2  \n",
       "9               10  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_shape': 101,\n",
       " 'nn3': 200,\n",
       " 'nn2': 512,\n",
       " 'nn1': 4096,\n",
       " 'lr': 0.001,\n",
       " 'input_shape': 7,\n",
       " 'decay': 1e-09,\n",
       " 'batch_size': 2048}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters after RandomizedSearchCV\n",
    "\n",
    "nn1 = 4096; nn2 = 512; nn3 = 200\n",
    "lr = 0.001; decay=1e-9\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularzation Parameters\n",
    "\n",
    "dropout = 0.5\n",
    "l1 = 0.0001\n",
    "l2 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nn1, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn2, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(nn3, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(NB_CLASSES, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_onehot = to_categorical(train_labels, NB_CLASSES)            #One Hot Encoder\n",
    "validation_labels_onehot = to_categorical(validation_labels, NB_CLASSES)  #One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307 samples, validate on 74 samples\n",
      "Epoch 1/32\n",
      "307/307 [==============================] - 44s 142ms/step - loss: 81.9862 - acc: 0.1010 - val_loss: 77.5625 - val_acc: 0.8243\n",
      "Epoch 2/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 78.2338 - acc: 0.5668 - val_loss: 75.0592 - val_acc: 0.8784\n",
      "Epoch 3/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 75.4331 - acc: 0.7752 - val_loss: 72.4291 - val_acc: 0.8649\n",
      "Epoch 4/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 72.6787 - acc: 0.8339 - val_loss: 69.6605 - val_acc: 0.9054\n",
      "Epoch 5/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 69.8011 - acc: 0.9055 - val_loss: 66.8113 - val_acc: 0.9054\n",
      "Epoch 6/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 66.9261 - acc: 0.9088 - val_loss: 63.9400 - val_acc: 0.9189\n",
      "Epoch 7/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 64.0132 - acc: 0.9316 - val_loss: 61.0847 - val_acc: 0.9189\n",
      "Epoch 8/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 61.1217 - acc: 0.9707 - val_loss: 58.2827 - val_acc: 0.9189\n",
      "Epoch 9/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 58.2861 - acc: 0.9739 - val_loss: 55.5648 - val_acc: 0.9189\n",
      "Epoch 10/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 55.5248 - acc: 0.9902 - val_loss: 52.9482 - val_acc: 0.9189\n",
      "Epoch 11/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 52.9004 - acc: 0.9902 - val_loss: 50.4622 - val_acc: 0.9324\n",
      "Epoch 12/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 50.4006 - acc: 0.9837 - val_loss: 48.1217 - val_acc: 0.9459\n",
      "Epoch 13/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 48.0724 - acc: 0.9805 - val_loss: 45.9497 - val_acc: 0.9459\n",
      "Epoch 14/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 45.8626 - acc: 0.9967 - val_loss: 43.9595 - val_acc: 0.9595\n",
      "Epoch 15/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 43.8820 - acc: 1.0000 - val_loss: 42.1583 - val_acc: 0.9595\n",
      "Epoch 16/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 42.0685 - acc: 1.0000 - val_loss: 40.4633 - val_acc: 0.9595\n",
      "Epoch 17/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 40.3676 - acc: 1.0000 - val_loss: 38.8191 - val_acc: 0.9595\n",
      "Epoch 18/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 38.7169 - acc: 1.0000 - val_loss: 37.2264 - val_acc: 0.9595\n",
      "Epoch 19/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 37.1274 - acc: 0.9967 - val_loss: 35.6714 - val_acc: 0.9595\n",
      "Epoch 20/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 35.5738 - acc: 0.9967 - val_loss: 34.1540 - val_acc: 0.9730\n",
      "Epoch 21/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 34.0490 - acc: 1.0000 - val_loss: 32.6798 - val_acc: 0.9730\n",
      "Epoch 22/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 32.5779 - acc: 1.0000 - val_loss: 31.2416 - val_acc: 0.9730\n",
      "Epoch 23/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 31.1259 - acc: 1.0000 - val_loss: 29.8560 - val_acc: 0.9730\n",
      "Epoch 24/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 29.7413 - acc: 1.0000 - val_loss: 28.5223 - val_acc: 0.9730\n",
      "Epoch 25/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 28.3997 - acc: 1.0000 - val_loss: 27.2493 - val_acc: 0.9730\n",
      "Epoch 26/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 27.1291 - acc: 1.0000 - val_loss: 26.0521 - val_acc: 0.9730\n",
      "Epoch 27/32\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 25.9225 - acc: 1.0000 - val_loss: 24.9291 - val_acc: 0.9595\n",
      "Epoch 28/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 24.7932 - acc: 1.0000 - val_loss: 23.8738 - val_acc: 0.9459\n",
      "Epoch 29/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 23.7395 - acc: 1.0000 - val_loss: 22.8863 - val_acc: 0.9324\n",
      "Epoch 30/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 22.7473 - acc: 1.0000 - val_loss: 21.9403 - val_acc: 0.9324\n",
      "Epoch 31/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 21.7910 - acc: 1.0000 - val_loss: 21.0243 - val_acc: 0.9324\n",
      "Epoch 32/32\n",
      "307/307 [==============================] - 3s 10ms/step - loss: 20.8668 - acc: 1.0000 - val_loss: 20.1480 - val_acc: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcba500f5f8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.fit(train_data, train_labels_onehot,\n",
    "              epochs=32,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.save_weights(top_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top():\n",
    "    opt = keras.optimizers.Adam(lr=lr)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                 \n",
    "    base= applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3)) #VGG16 trained on imagenet\n",
    "    \n",
    "    top = Sequential()\n",
    "\n",
    "    top.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    top.add(Dense(nn1, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())\n",
    "    top.add(Dense(nn2, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())\n",
    "    top.add(Dense(nn3, activation='relu', kernel_regularizer=reg))\n",
    "    top.add(BatchNormalization())            \n",
    "    top.add(Dense(NB_CLASSES, activation='softmax'))\n",
    "    top.load_weights(top_weights_file)\n",
    "    top.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    \n",
    "    \n",
    "    model = Model(input= base.input, output= top(base.output))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_43 (Sequential)   (None, 11)                104986251 \n",
      "=================================================================\n",
      "Total params: 119,700,939\n",
      "Trainable params: 0\n",
      "Non-trainable params: 119,700,939\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = top()\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "print(\"Model Summary\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 11 classes.\n",
      "1/1 [==============================] - 15s 15s/step\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "            test_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=len(test_labels),\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "test_predictions = model.predict_generator(generator, 1, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.asarray(list(map(str,np.argmax(test_predictions,axis=1)))).reshape(-1,1)\n",
    "test_labels = np.asarray(test_labels).reshape(-1,1)\n",
    "test_acc, test_acc_op = tf.metrics.accuracy(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = sess.run(test_acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy : 0.9444444\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest accuracy : ' + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
