{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning : Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'Data/Training_Data'\n",
    "validation_data_dir = 'Data/Validation_Data'\n",
    "test_data_dir= 'Data/Test_Data'\n",
    "\n",
    "train_labels_file = 'Labels/training_labels.npy'\n",
    "validation_labels_file = 'Labels/validation_labels.npy'\n",
    "test_labels_file = 'Labels/test_labels.npy'\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "NB_CLASSES = 10\n",
    "epochs = 16\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(open(train_labels_file, 'rb'))\n",
    "validation_labels = np.load(open(validation_labels_file, 'rb'))\n",
    "test_labels = np.load(open(test_labels_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to feature vectors using weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_feature_vectors(model, directory, batch_size, steps):\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False) # Keep the data in the same order\n",
    "    \n",
    "    features = model.predict_generator(generator, steps, verbose=1) \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the top part of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_model(training_features, validation_features, batch_size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=training_features.shape[1:], name='Main_input'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1096, activation='relu', name='D1'))\n",
    "    model.add(Dense(512, activation='relu', name='D2'))\n",
    "    model.add(Dense(NB_CLASSES, activation='softmax', name='Main_output'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    train_labels_onehot = to_categorical(train_labels, NB_CLASSES)            #One Hot Encoder\n",
    "    validation_labels_onehot = to_categorical(validation_labels, NB_CLASSES)  #One Hot Encoder\n",
    "    \n",
    "    model.fit(training_features, train_labels_onehot,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_features, validation_labels_onehot))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 78s 253ms/step\n",
      "Found 76 images belonging to 11 classes.\n",
      "76/76 [==============================] - 20s 259ms/step\n",
      "Features extraction time : 0:01:38.691649\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Batch size has to be a multiple of the number of images  to keep our vectors consistents\n",
    "training_batch_size = 1 # batch size for feature pre-training\n",
    "validation_batch_size = 1 # batch size for feature pre-training\n",
    "\n",
    "model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3)) #VGG16 trained on imagenet\n",
    "training_features = images_to_feature_vectors(model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)\n",
    "\n",
    "end_time = datetime.now()\n",
    "features_extraction_time = end_time - start_time\n",
    "print('Features extraction time : {}'.format(features_extraction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 307 samples, validate on 76 samples\n",
      "Epoch 1/16\n",
      "307/307 [==============================] - 3s 11ms/step - loss: 2.5939 - acc: 0.0814 - val_loss: 1.9731 - val_acc: 0.7895\n",
      "Epoch 2/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9935 - val_loss: 2.3592 - val_acc: 0.7763\n",
      "Epoch 3/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 6.4147e-04 - acc: 1.0000 - val_loss: 2.6924 - val_acc: 0.7632\n",
      "Epoch 4/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.6963 - val_acc: 0.7763\n",
      "Epoch 5/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.6011 - val_acc: 0.7763\n",
      "Epoch 6/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 2.3079e-04 - acc: 1.0000 - val_loss: 2.5138 - val_acc: 0.7895\n",
      "Epoch 7/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 1.6356e-04 - acc: 1.0000 - val_loss: 2.4447 - val_acc: 0.7895\n",
      "Epoch 8/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 1.0598e-04 - acc: 1.0000 - val_loss: 2.3994 - val_acc: 0.7895\n",
      "Epoch 9/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 7.0116e-05 - acc: 1.0000 - val_loss: 2.3471 - val_acc: 0.7895\n",
      "Epoch 10/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 4.8595e-05 - acc: 1.0000 - val_loss: 2.2955 - val_acc: 0.7895\n",
      "Epoch 11/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 3.5798e-05 - acc: 1.0000 - val_loss: 2.2570 - val_acc: 0.7895\n",
      "Epoch 12/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 2.7948e-05 - acc: 1.0000 - val_loss: 2.2247 - val_acc: 0.7895\n",
      "Epoch 13/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 2.2358e-05 - acc: 1.0000 - val_loss: 2.1974 - val_acc: 0.8026\n",
      "Epoch 14/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 1.8512e-05 - acc: 1.0000 - val_loss: 2.1716 - val_acc: 0.8026\n",
      "Epoch 15/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 1.6008e-05 - acc: 1.0000 - val_loss: 2.1494 - val_acc: 0.8026\n",
      "Epoch 16/16\n",
      "307/307 [==============================] - 1s 4ms/step - loss: 1.3228e-05 - acc: 1.0000 - val_loss: 2.1305 - val_acc: 0.8026\n",
      "Total training duration : 0:00:21.799088\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = top_model(training_features, validation_features, batch_size, epochs)\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = end_time - start_time\n",
    "print('Total training duration : {}'.format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_labels_onehot = to_categorical(train_labels, NB_CLASSES)\n",
    "loss, training_accuracy = model.evaluate(training_features,train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "validation_labels_onehot = to_categorical(validation_labels, NB_CLASSES)\n",
    "loss, validation_accuracy = model.evaluate(validation_features,validation_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training Accuracy : 100.0%'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Training Accuracy : '+ str(round(training_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation Accuracy : 80.3%'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Validation Accuracy : '+ str(round(validation_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_results = (round(training_accuracy*100,1), round(validation_accuracy*100,1), round(features_extraction_time.total_seconds()), round(training_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 47s 153ms/step\n",
      "Found 76 images belonging to 11 classes.\n",
      "76/76 [==============================] - 11s 147ms/step\n",
      "Features extraction time : 0:01:18.440715\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3)) #VGG16 trained on imagenet\n",
    "training_features = images_to_feature_vectors(model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)\n",
    "\n",
    "end_time = datetime.now()\n",
    "features_extraction_time = end_time - start_time\n",
    "print('Features extraction time : {}'.format(features_extraction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307 samples, validate on 76 samples\n",
      "Epoch 1/16\n",
      "307/307 [==============================] - 7s 23ms/step - loss: 2.7096 - acc: 0.0847 - val_loss: 8.6085 - val_acc: 0.3816\n",
      "Epoch 2/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 4.8481 - acc: 0.6091 - val_loss: 8.7810 - val_acc: 0.4079\n",
      "Epoch 3/16\n",
      "307/307 [==============================] - 2s 7ms/step - loss: 3.8912 - acc: 0.7101 - val_loss: 9.0170 - val_acc: 0.4079\n",
      "Epoch 4/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 3.6917 - acc: 0.7101 - val_loss: 8.6848 - val_acc: 0.3947\n",
      "Epoch 5/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 3.5178 - acc: 0.7557 - val_loss: 8.4848 - val_acc: 0.4211\n",
      "Epoch 6/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 3.3727 - acc: 0.7655 - val_loss: 7.8308 - val_acc: 0.4211\n",
      "Epoch 7/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 3.3574 - acc: 0.7622 - val_loss: 7.8906 - val_acc: 0.4605\n",
      "Epoch 8/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 2.8333 - acc: 0.7980 - val_loss: 7.9763 - val_acc: 0.4342\n",
      "Epoch 9/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 2.5167 - acc: 0.8306 - val_loss: 7.8527 - val_acc: 0.4474\n",
      "Epoch 10/16\n",
      "307/307 [==============================] - 2s 7ms/step - loss: 2.1855 - acc: 0.8534 - val_loss: 7.2277 - val_acc: 0.5000\n",
      "Epoch 11/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.8794 - acc: 0.8762 - val_loss: 6.4545 - val_acc: 0.5526\n",
      "Epoch 12/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.8440 - acc: 0.8795 - val_loss: 6.1945 - val_acc: 0.5658\n",
      "Epoch 13/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.6137 - acc: 0.8958 - val_loss: 6.0919 - val_acc: 0.6053\n",
      "Epoch 14/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.5781 - acc: 0.9023 - val_loss: 5.7836 - val_acc: 0.6053\n",
      "Epoch 15/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.5879 - acc: 0.8990 - val_loss: 6.2384 - val_acc: 0.5921\n",
      "Epoch 16/16\n",
      "307/307 [==============================] - 2s 8ms/step - loss: 1.5156 - acc: 0.9023 - val_loss: 6.0443 - val_acc: 0.5921\n",
      "Total training duration : 0:00:43.315854\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = top_model(training_features, validation_features, batch_size, epochs)\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = end_time - start_time\n",
    "print('Total training duration : {}'.format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, training_accuracy = model.evaluate(training_features,train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, validation_accuracy = model.evaluate(validation_features,validation_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training Accuracy : 88.9%'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Training Accuracy : '+ str(round(training_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation Accuracy : 59.2%'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Validation Accuracy : '+ str(round(validation_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_results = (round(training_accuracy*100,1), round(validation_accuracy*100,1), round(features_extraction_time.total_seconds()), round(training_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 61s 197ms/step\n",
      "Found 76 images belonging to 11 classes.\n",
      "76/76 [==============================] - 14s 187ms/step\n",
      "Features extraction time : 0:01:30.207649\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3)) #VGG16 trained on imagenet\n",
    "training_features = images_to_feature_vectors(model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)\n",
    "\n",
    "end_time = datetime.now()\n",
    "features_extraction_time = end_time - start_time\n",
    "print('Features extraction time : {}'.format(features_extraction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307 samples, validate on 76 samples\n",
      "Epoch 1/16\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 2.8549 - acc: 0.1107 - val_loss: 1.4155 - val_acc: 0.8684\n",
      "Epoch 2/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 2.8593e-06 - acc: 1.0000 - val_loss: 2.2279 - val_acc: 0.8158\n",
      "Epoch 3/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 0.0597 - acc: 0.9935 - val_loss: 3.0368 - val_acc: 0.7895\n",
      "Epoch 4/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 0.2218 - acc: 0.9772 - val_loss: 2.7831 - val_acc: 0.8158\n",
      "Epoch 5/16\n",
      "307/307 [==============================] - 4s 15ms/step - loss: 0.0639 - acc: 0.9935 - val_loss: 2.2545 - val_acc: 0.8289\n",
      "Epoch 6/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 1.6728e-05 - acc: 1.0000 - val_loss: 1.9604 - val_acc: 0.8553\n",
      "Epoch 7/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 0.0410 - acc: 0.9967 - val_loss: 1.6160 - val_acc: 0.8947\n",
      "Epoch 8/16\n",
      "307/307 [==============================] - 4s 15ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.4944 - val_acc: 0.8947\n",
      "Epoch 9/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.3677 - val_acc: 0.9079\n",
      "Epoch 10/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 3.0113e-07 - acc: 1.0000 - val_loss: 1.1912 - val_acc: 0.9079\n",
      "Epoch 11/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 4.9176e-05 - acc: 1.0000 - val_loss: 1.0617 - val_acc: 0.9342\n",
      "Epoch 12/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 1.9683e-06 - acc: 1.0000 - val_loss: 1.2739 - val_acc: 0.9211\n",
      "Epoch 13/16\n",
      "307/307 [==============================] - 4s 15ms/step - loss: 2.3493e-07 - acc: 1.0000 - val_loss: 1.2983 - val_acc: 0.9079\n",
      "Epoch 14/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 1.3785e-07 - acc: 1.0000 - val_loss: 1.3460 - val_acc: 0.9079\n",
      "Epoch 15/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 3.1958e-07 - acc: 1.0000 - val_loss: 1.6948 - val_acc: 0.8684\n",
      "Epoch 16/16\n",
      "307/307 [==============================] - 5s 15ms/step - loss: 3.6224e-06 - acc: 1.0000 - val_loss: 2.0760 - val_acc: 0.8684\n",
      "Total training duration : 0:01:22.040374\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = top_model(training_features, validation_features, batch_size, epochs)\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = end_time - start_time\n",
    "print('Total training duration : {}'.format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, training_accuracy = model.evaluate(training_features,train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, validation_accuracy = model.evaluate(validation_features,validation_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training Accuracy : 100.0%'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Training Accuracy : '+ str(round(training_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation Accuracy : 86.8%'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Validation Accuracy : '+ str(round(validation_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_results = (round(training_accuracy*100,1), round(validation_accuracy*100,1), round(features_extraction_time.total_seconds()), round(training_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 5s 0us/step\n",
      "Found 307 images belonging to 11 classes.\n",
      "307/307 [==============================] - 109s 356ms/step\n",
      "Found 76 images belonging to 11 classes.\n",
      "76/76 [==============================] - 25s 332ms/step\n",
      "Features extraction time : 0:03:16.499488\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = applications.DenseNet201(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3)) #VGG16 trained on imagenet\n",
    "training_features = images_to_feature_vectors(model, train_data_dir, training_batch_size, len(train_labels) // training_batch_size)\n",
    "validation_features = images_to_feature_vectors(model, validation_data_dir, validation_batch_size, len(validation_labels) // validation_batch_size)\n",
    "\n",
    "end_time = datetime.now()\n",
    "features_extraction_time = end_time - start_time\n",
    "print('Features extraction time : {}'.format(features_extraction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 307 samples, validate on 76 samples\n",
      "Epoch 1/16\n",
      "307/307 [==============================] - 19s 61ms/step - loss: 2.6089 - acc: 0.0977 - val_loss: 1.8228 - val_acc: 0.8158\n",
      "Epoch 2/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.2482 - acc: 0.9511 - val_loss: 1.6161 - val_acc: 0.8684\n",
      "Epoch 3/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0834 - acc: 0.9902 - val_loss: 1.8055 - val_acc: 0.8553\n",
      "Epoch 4/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0898 - acc: 0.9902 - val_loss: 1.8348 - val_acc: 0.8421\n",
      "Epoch 5/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0681 - acc: 0.9935 - val_loss: 1.8872 - val_acc: 0.8553\n",
      "Epoch 6/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0461 - acc: 0.9967 - val_loss: 2.1938 - val_acc: 0.8421\n",
      "Epoch 7/16\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 0.0647 - acc: 0.9935 - val_loss: 2.5384 - val_acc: 0.7895\n",
      "Epoch 8/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0746 - acc: 0.9935 - val_loss: 2.6356 - val_acc: 0.8026\n",
      "Epoch 9/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0606 - acc: 0.9935 - val_loss: 2.3223 - val_acc: 0.8158\n",
      "Epoch 10/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0525 - acc: 0.9967 - val_loss: 2.1358 - val_acc: 0.8158\n",
      "Epoch 11/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0440 - acc: 0.9967 - val_loss: 2.4228 - val_acc: 0.8289\n",
      "Epoch 12/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0478 - acc: 0.9967 - val_loss: 2.5388 - val_acc: 0.8289\n",
      "Epoch 13/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 5.0968e-06 - acc: 1.0000 - val_loss: 2.4558 - val_acc: 0.8421\n",
      "Epoch 14/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 2.1177e-06 - acc: 1.0000 - val_loss: 2.3766 - val_acc: 0.8421\n",
      "Epoch 15/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.0567 - acc: 0.9935 - val_loss: 1.9782 - val_acc: 0.8684\n",
      "Epoch 16/16\n",
      "307/307 [==============================] - 4s 14ms/step - loss: 0.1104 - acc: 0.9902 - val_loss: 2.2012 - val_acc: 0.8421\n",
      "Total training duration : 0:01:23.155078\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "model = top_model(training_features, validation_features, batch_size, epochs)\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = end_time - start_time\n",
    "print('Total training duration : {}'.format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, training_accuracy = model.evaluate(training_features,train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, validation_accuracy = model.evaluate(validation_features,validation_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training Accuracy : 98.7%'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Training Accuracy : '+ str(round(training_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation Accuracy : 84.2%'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Validation Accuracy : '+ str(round(validation_accuracy*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_results = (round(training_accuracy*100,1), round(validation_accuracy*100,1), round(features_extraction_time.total_seconds()), round(training_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Model': ['VGG16', 'Inception', 'Resnet', 'Densnet'], \n",
    "           'Training Accuracy(%)': [vgg16_results[0], inception_results[0], resnet_results[0], densenet_results[0]],\n",
    "           'Validation Accuracy(%)': [vgg16_results[1], inception_results[1], resnet_results[1], densenet_results[1]],\n",
    "           'Features Extraction time(s)': [vgg16_results[2], inception_results[2], resnet_results[2], densenet_results[2]],\n",
    "           'Training time(s)': [vgg16_results[3], inception_results[3], resnet_results[3], densenet_results[3]]}\n",
    "df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy(%)</th>\n",
       "      <th>Validation Accuracy(%)</th>\n",
       "      <th>Features Extraction time(s)</th>\n",
       "      <th>Training time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.3</td>\n",
       "      <td>99</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inception</td>\n",
       "      <td>88.9</td>\n",
       "      <td>59.2</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resnet</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>90</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Densnet</td>\n",
       "      <td>98.7</td>\n",
       "      <td>84.2</td>\n",
       "      <td>196</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Training Accuracy(%)  Validation Accuracy(%)  \\\n",
       "0      VGG16                 100.0                    80.3   \n",
       "1  Inception                  88.9                    59.2   \n",
       "2     Resnet                 100.0                    86.8   \n",
       "3    Densnet                  98.7                    84.2   \n",
       "\n",
       "   Features Extraction time(s)  Training time(s)  \n",
       "0                           99                22  \n",
       "1                           78                43  \n",
       "2                           90                82  \n",
       "3                          196                83  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
